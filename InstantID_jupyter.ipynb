{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhnanjay/HuggingFace/blob/main/InstantID_jupyter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "outputId": "3cfee94f-473e-47b0-affd-b851ca339fe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'InstantID-hf'...\n",
            "remote: Enumerating objects: 72, done.\u001b[K\n",
            "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 72 (delta 28), reused 67 (delta 24), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (72/72), 415.88 KiB | 8.15 MiB/s, done.\n",
            "Resolving deltas: 100% (28/28), done.\n",
            "Downloading examples/kaifu_resize.png (1.1 MB)\n",
            "Error downloading object: examples/kaifu_resize.png (b7302f0): Smudge error: Error downloading examples/kaifu_resize.png (b7302f0f7d0ff61be67bf13d172ad2393b6cb2bc985f048089f4e901145324d7): [b7302f0f7d0ff61be67bf13d172ad2393b6cb2bc985f048089f4e901145324d7] Object does not exist on the server: [404] Object does not exist on the server\n",
            "\n",
            "Errors logged to /content/InstantID-hf/.git/lfs/logs/20240227T200905.106884963.log\n",
            "Use `git lfs logs last` to view the log.\n",
            "error: external filter 'git-lfs filter-process' failed\n",
            "fatal: examples/kaifu_resize.png: smudge filter lfs failed\n",
            "warning: Clone succeeded, but checkout failed.\n",
            "You can inspect what was checked out with 'git status'\n",
            "and retry with 'git restore --source=HEAD :/'\n",
            "\n",
            "/content/InstantID-hf\n",
            "The following additional packages will be installed:\n",
            "  libaria2-0 libc-ares2\n",
            "The following NEW packages will be installed:\n",
            "  aria2 libaria2-0 libc-ares2\n",
            "0 upgraded, 3 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 1,513 kB of archives.\n",
            "After this operation, 5,441 kB of additional disk space will be used.\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "(Reading database ... 121749 files and directories currently installed.)\n",
            "Preparing to unpack .../libc-ares2_1.18.1-1ubuntu0.22.04.2_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.2) ...\n",
            "Selecting previously unselected package libaria2-0:amd64.\n",
            "Preparing to unpack .../libaria2-0_1.36.0-1_amd64.deb ...\n",
            "Unpacking libaria2-0:amd64 (1.36.0-1) ...\n",
            "Selecting previously unselected package aria2.\n",
            "Preparing to unpack .../aria2_1.36.0-1_amd64.deb ...\n",
            "Unpacking aria2 (1.36.0-1) ...\n",
            "Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.2) ...\n",
            "Setting up libaria2-0:amd64 (1.36.0-1) ...\n",
            "Setting up aria2 (1.36.0-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "6ed973|\u001b[1;32mOK\u001b[0m  |   167KiB/s|/content/InstantID-hf/checkpoints/ControlNetModel/config.json\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "06dbe0|\u001b[1;32mOK\u001b[0m  |   230MiB/s|/content/InstantID-hf/checkpoints/ControlNetModel/diffusion_pytorch_model.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "6f28ba|\u001b[1;32mOK\u001b[0m  |   244MiB/s|/content/InstantID-hf/checkpoints/ip-adapter.bin\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "71d780|\u001b[1;32mOK\u001b[0m  |   217MiB/s|/content/InstantID-hf/models/antelopev2/1k3d68.onnx\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "3b203c|\u001b[1;32mOK\u001b[0m  |    31MiB/s|/content/InstantID-hf/models/antelopev2/2d106det.onnx\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "c605e6|\u001b[1;32mOK\u001b[0m  |   9.6MiB/s|/content/InstantID-hf/models/antelopev2/genderage.onnx\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "f0af60|\u001b[1;32mOK\u001b[0m  |   209MiB/s|/content/InstantID-hf/models/antelopev2/glintr100.onnx\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "3c1b53|\u001b[1;32mOK\u001b[0m  |    38MiB/s|/content/InstantID-hf/models/antelopev2/scrfd_10g_bnkps.onnx\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "b3f685|\u001b[1;32mOK\u001b[0m  |   8.2MiB/s|/content/InstantID-hf/examples/kaifu_resize.png\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "0032e3|\u001b[1;32mOK\u001b[0m  |    15MiB/s|/content/InstantID-hf/examples/sam_resize.png\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "5805d1|\u001b[1;32mOK\u001b[0m  |    22MiB/s|/content/InstantID-hf/examples/schmidhuber_resize.png\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hThe cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
            "0it [00:00, ?it/s]\n",
            "2024-02-27 20:11:05.303288: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-27 20:11:05.303344: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-27 20:11:05.304767: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-27 20:11:06.441312: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
            "  warnings.warn(\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: ./models/antelopev2/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: ./models/antelopev2/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: ./models/antelopev2/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: ./models/antelopev2/glintr100.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: ./models/antelopev2/scrfd_10g_bnkps.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "set det-size: (640, 640)\n",
            "model_index.json: 100% 800/800 [00:00<00:00, 4.15MB/s]\n",
            "Fetching 18 files:   0% 0/18 [00:00<?, ?it/s]\n",
            "tokenizer/tokenizer_config.json: 100% 737/737 [00:00<00:00, 3.78MB/s]\n",
            "\n",
            "text_encoder_2/config.json: 100% 688/688 [00:00<00:00, 4.35MB/s]\n",
            "\n",
            "scheduler/scheduler_config.json: 100% 474/474 [00:00<00:00, 3.61MB/s]\n",
            "Fetching 18 files:  11% 2/18 [00:00<00:04,  3.54it/s]\n",
            "text_encoder/config.json: 100% 676/676 [00:00<00:00, 3.06MB/s]\n",
            "\n",
            "tokenizer/special_tokens_map.json: 100% 472/472 [00:00<00:00, 2.55MB/s]\n",
            "\n",
            "tokenizer/vocab.json:   0% 0.00/1.06M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "tokenizer_2/special_tokens_map.json: 100% 460/460 [00:00<00:00, 2.49MB/s]\n",
            "\n",
            "\n",
            "model.safetensors:   0% 0.00/246M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   0% 0.00/1.39G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizer/merges.txt:   0% 0.00/525k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizer_2/tokenizer_config.json: 100% 725/725 [00:00<00:00, 2.16MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "unet/config.json: 100% 1.83k/1.83k [00:00<00:00, 8.96MB/s]\n",
            "tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 6.02MB/s]\n",
            "\n",
            "\n",
            "model.safetensors:   4% 10.5M/246M [00:00<00:04, 52.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   1% 10.5M/1.39G [00:00<00:26, 51.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizer_2/merges.txt:   0% 0.00/525k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   9% 21.0M/246M [00:00<00:03, 74.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "vae/config.json:   0% 0.00/709 [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "vae/config.json: 100% 709/709 [00:00<00:00, 658kB/s]\n",
            "\n",
            "\n",
            "\n",
            "tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 2.82MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizer_2/merges.txt: 100% 525k/525k [00:00<00:00, 3.03MB/s]\n",
            "\n",
            "\n",
            "model.safetensors:  17% 41.9M/246M [00:00<00:02, 91.1MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   0% 0.00/5.14G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   3% 41.9M/1.39G [00:00<00:15, 89.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizer_2/vocab.json:   0% 0.00/1.06M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   0% 0.00/167M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  26% 62.9M/246M [00:00<00:01, 101MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   5% 62.9M/1.39G [00:00<00:13, 99.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   0% 10.5M/5.14G [00:00<02:15, 37.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:   6% 10.5M/167M [00:00<00:04, 38.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  30% 73.4M/246M [00:00<00:01, 88.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   5% 73.4M/1.39G [00:00<00:15, 87.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   0% 21.0M/5.14G [00:00<01:35, 53.5MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  34% 83.9M/246M [00:00<00:01, 87.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  13% 21.0M/167M [00:00<00:02, 51.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   6% 83.9M/1.39G [00:01<00:15, 83.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   1% 31.5M/5.14G [00:00<01:26, 58.9MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  38% 94.4M/246M [00:01<00:01, 81.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  19% 31.5M/167M [00:00<00:02, 58.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   7% 94.4M/1.39G [00:01<00:14, 87.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   1% 41.9M/5.14G [00:00<01:15, 67.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  25% 41.9M/167M [00:00<00:01, 63.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizer_2/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 1.42MB/s]\n",
            "\n",
            "\n",
            "model.safetensors:  43% 105M/246M [00:01<00:01, 73.7MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   8% 105M/1.39G [00:01<00:16, 77.8MB/s] \u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   1% 52.4M/5.14G [00:00<01:08, 73.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   8% 115M/1.39G [00:01<00:15, 80.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  47% 115M/246M [00:01<00:01, 75.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  31% 52.4M/167M [00:00<00:01, 63.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   1% 62.9M/5.14G [00:00<01:11, 71.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:   9% 126M/1.39G [00:01<00:16, 76.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  38% 62.9M/167M [00:01<00:01, 65.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  51% 126M/246M [00:01<00:01, 73.3MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   1% 73.4M/5.14G [00:01<01:07, 74.7MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  55% 136M/246M [00:01<00:01, 72.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  44% 73.4M/167M [00:01<00:01, 65.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  10% 136M/1.39G [00:01<00:17, 71.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   2% 83.9M/5.14G [00:01<01:10, 72.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  50% 83.9M/167M [00:01<00:01, 65.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  60% 147M/246M [00:01<00:01, 66.8MB/s]\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   2% 94.4M/5.14G [00:01<01:11, 70.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  11% 147M/1.39G [00:01<00:18, 67.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  56% 94.4M/167M [00:01<00:01, 71.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  64% 157M/246M [00:02<00:01, 70.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  11% 157M/1.39G [00:02<00:18, 65.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   2% 105M/5.14G [00:01<01:16, 66.0MB/s] \u001b[A\n",
            "\n",
            "model.safetensors:  68% 168M/246M [00:02<00:01, 73.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  63% 105M/167M [00:01<00:00, 68.9MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  12% 168M/1.39G [00:02<00:17, 69.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   2% 115M/5.14G [00:01<01:13, 68.5MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  72% 178M/246M [00:02<00:00, 75.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  69% 115M/167M [00:01<00:00, 70.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  13% 178M/1.39G [00:02<00:16, 72.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   2% 126M/5.14G [00:01<01:12, 69.0MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  77% 189M/246M [00:02<00:00, 78.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  75% 126M/167M [00:01<00:00, 70.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  14% 189M/1.39G [00:02<00:16, 72.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   3% 136M/5.14G [00:02<01:08, 73.2MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  81% 199M/246M [00:02<00:00, 79.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  81% 136M/167M [00:02<00:00, 75.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  14% 199M/1.39G [00:02<00:16, 73.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   3% 147M/5.14G [00:02<01:07, 74.3MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  85% 210M/246M [00:02<00:00, 80.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  15% 210M/1.39G [00:02<00:14, 79.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   3% 157M/5.14G [00:02<01:02, 79.1MB/s]\u001b[A\n",
            "\n",
            "model.safetensors:  89% 220M/246M [00:02<00:00, 82.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors:  94% 157M/167M [00:02<00:00, 84.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  16% 220M/1.39G [00:02<00:14, 82.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  94% 231M/246M [00:02<00:00, 86.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors: 100% 246M/246M [00:03<00:00, 80.8MB/s]\n",
            "Fetching 18 files:  22% 4/18 [00:03<00:14,  1.07s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.safetensors: 100% 167M/167M [00:02<00:00, 66.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors: 100% 167M/167M [00:02<00:00, 64.3MB/s]\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  17% 231M/1.39G [00:03<00:20, 57.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   3% 178M/5.14G [00:02<01:22, 60.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  17% 241M/1.39G [00:03<00:17, 64.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   4% 189M/5.14G [00:02<01:13, 66.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  18% 252M/1.39G [00:03<00:16, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   4% 199M/5.14G [00:02<01:09, 70.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  19% 262M/1.39G [00:04<00:34, 33.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   4% 210M/5.14G [00:06<08:00, 10.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  20% 273M/1.39G [00:07<02:12, 8.42MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   4% 220M/5.14G [00:07<07:56, 10.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  20% 283M/1.39G [00:07<01:35, 11.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   5% 241M/5.14G [00:07<04:38, 17.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  22% 304M/1.39G [00:07<00:54, 19.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   5% 262M/5.14G [00:07<03:02, 26.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  23% 325M/1.39G [00:08<00:36, 29.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   5% 273M/5.14G [00:07<02:52, 28.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  24% 336M/1.39G [00:08<00:34, 30.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   6% 283M/5.14G [00:07<02:22, 34.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  26% 357M/1.39G [00:08<00:24, 42.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   6% 304M/5.14G [00:08<01:42, 47.1MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   6% 315M/5.14G [00:08<01:33, 51.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  27% 377M/1.39G [00:08<00:19, 51.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  28% 388M/1.39G [00:08<00:17, 56.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   7% 336M/5.14G [00:08<01:16, 63.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  29% 409M/1.39G [00:09<00:14, 67.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   7% 357M/5.14G [00:08<01:05, 73.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  30% 419M/1.39G [00:09<00:13, 72.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   7% 367M/5.14G [00:08<01:01, 77.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  32% 440M/1.39G [00:09<00:11, 84.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   8% 388M/5.14G [00:08<00:53, 88.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  32% 451M/1.39G [00:09<00:11, 85.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   8% 409M/5.14G [00:09<00:50, 93.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  33% 461M/1.39G [00:09<00:10, 87.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   8% 419M/5.14G [00:09<00:50, 92.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  35% 482M/1.39G [00:09<00:10, 87.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   8% 430M/5.14G [00:09<00:53, 88.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  35% 493M/1.39G [00:09<00:10, 84.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   9% 440M/5.14G [00:09<00:55, 85.3MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   9% 451M/5.14G [00:09<00:54, 85.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  36% 503M/1.39G [00:10<00:10, 82.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   9% 461M/5.14G [00:09<00:55, 83.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  37% 514M/1.39G [00:10<00:10, 82.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   9% 472M/5.14G [00:09<00:56, 83.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  38% 524M/1.39G [00:10<00:10, 81.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:   9% 482M/5.14G [00:11<03:33, 21.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  38% 535M/1.39G [00:12<00:49, 17.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  10% 493M/5.14G [00:12<04:15, 18.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  39% 545M/1.39G [00:12<00:42, 19.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  10% 503M/5.14G [00:12<03:18, 23.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  40% 556M/1.39G [00:12<00:33, 24.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  10% 514M/5.14G [00:12<02:52, 26.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  41% 566M/1.39G [00:12<00:29, 27.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  10% 524M/5.14G [00:12<02:15, 34.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  42% 577M/1.39G [00:13<00:23, 35.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  11% 545M/5.14G [00:12<01:30, 50.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  43% 598M/1.39G [00:13<00:15, 51.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  11% 566M/5.14G [00:12<01:13, 62.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  45% 619M/1.39G [00:13<00:11, 64.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  11% 577M/5.14G [00:13<01:07, 67.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  45% 629M/1.39G [00:13<00:11, 64.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  12% 598M/5.14G [00:13<00:57, 78.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  47% 650M/1.39G [00:13<00:09, 76.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  12% 608M/5.14G [00:13<00:54, 82.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  48% 661M/1.39G [00:13<00:09, 80.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  12% 619M/5.14G [00:16<05:36, 13.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  48% 671M/1.39G [00:17<01:05, 10.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  12% 629M/5.14G [00:17<05:54, 12.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  49% 682M/1.39G [00:17<00:52, 13.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  12% 640M/5.14G [00:17<04:42, 15.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  50% 692M/1.39G [00:17<00:40, 17.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  13% 650M/5.14G [00:17<03:37, 20.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  51% 703M/1.39G [00:18<00:30, 22.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  13% 671M/5.14G [00:17<02:20, 31.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  52% 724M/1.39G [00:18<00:19, 34.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  13% 692M/5.14G [00:17<01:40, 44.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  54% 744M/1.39G [00:18<00:13, 47.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  14% 713M/5.14G [00:18<01:17, 57.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  55% 765M/1.39G [00:18<00:10, 60.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  14% 734M/5.14G [00:18<01:04, 68.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  57% 786M/1.39G [00:18<00:08, 72.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  14% 744M/5.14G [00:18<01:00, 72.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  58% 807M/1.39G [00:19<00:08, 72.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  15% 755M/5.14G [00:18<01:04, 67.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  59% 818M/1.39G [00:19<00:07, 75.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  15% 765M/5.14G [00:18<01:00, 71.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  60% 828M/1.39G [00:19<00:07, 78.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  15% 786M/5.14G [00:18<00:52, 82.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  60% 839M/1.39G [00:19<00:06, 83.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  62% 860M/1.39G [00:19<00:05, 93.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  16% 797M/5.14G [00:19<01:11, 60.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  63% 881M/1.39G [00:19<00:04, 104MB/s] \u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  16% 807M/5.14G [00:19<01:04, 67.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  65% 902M/1.39G [00:19<00:04, 108MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  16% 828M/5.14G [00:19<00:52, 81.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  66% 923M/1.39G [00:20<00:04, 113MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  16% 839M/5.14G [00:19<00:50, 85.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  68% 944M/1.39G [00:20<00:04, 111MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  17% 860M/5.14G [00:19<00:46, 91.3MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  17% 870M/5.14G [00:19<00:47, 88.9MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  17% 881M/5.14G [00:20<00:46, 92.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  69% 965M/1.39G [00:20<00:04, 100MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  17% 891M/5.14G [00:20<00:48, 87.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  70% 975M/1.39G [00:20<00:04, 93.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  18% 902M/5.14G [00:20<00:46, 91.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  71% 986M/1.39G [00:20<00:04, 93.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  18% 912M/5.14G [00:21<03:45, 18.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  72% 996M/1.39G [00:22<00:18, 21.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  72% 1.01G/1.39G [00:22<00:15, 24.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  18% 933M/5.14G [00:22<02:36, 26.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  73% 1.02G/1.39G [00:22<00:12, 30.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  18% 944M/5.14G [00:22<02:09, 32.3MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  19% 954M/5.14G [00:22<01:48, 38.7MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  19% 975M/5.14G [00:22<01:16, 54.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  75% 1.04G/1.39G [00:23<00:09, 35.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  19% 996M/5.14G [00:22<01:02, 66.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  75% 1.05G/1.39G [00:23<00:08, 41.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  76% 1.06G/1.39G [00:25<00:19, 16.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  20% 1.01G/5.14G [00:24<03:23, 20.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  77% 1.07G/1.39G [00:25<00:15, 20.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  20% 1.02G/5.14G [00:24<02:54, 23.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  78% 1.08G/1.39G [00:25<00:12, 25.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  20% 1.03G/5.14G [00:25<02:25, 28.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  78% 1.09G/1.39G [00:25<00:09, 31.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  20% 1.04G/5.14G [00:25<01:59, 34.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  80% 1.11G/1.39G [00:25<00:06, 46.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  21% 1.06G/5.14G [00:25<01:23, 48.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  82% 1.13G/1.39G [00:26<00:04, 61.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  21% 1.08G/5.14G [00:25<01:05, 61.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  83% 1.15G/1.39G [00:26<00:03, 73.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  21% 1.10G/5.14G [00:25<00:55, 73.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  85% 1.17G/1.39G [00:26<00:02, 81.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  22% 1.12G/5.14G [00:26<00:51, 77.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  85% 1.18G/1.39G [00:26<00:02, 79.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  22% 1.14G/5.14G [00:26<00:45, 87.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  87% 1.21G/1.39G [00:26<00:02, 89.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  23% 1.16G/5.14G [00:26<00:43, 91.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  88% 1.23G/1.39G [00:26<00:01, 95.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  89% 1.24G/1.39G [00:27<00:01, 97.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  23% 1.17G/5.14G [00:26<00:43, 91.9MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  23% 1.18G/5.14G [00:26<00:43, 91.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  90% 1.25G/1.39G [00:27<00:01, 93.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  23% 1.20G/5.14G [00:26<00:42, 92.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  91% 1.27G/1.39G [00:27<00:01, 97.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  23% 1.21G/5.14G [00:26<00:41, 93.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  92% 1.28G/1.39G [00:27<00:01, 96.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  24% 1.22G/5.14G [00:27<00:41, 93.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  93% 1.29G/1.39G [00:27<00:01, 95.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  24% 1.23G/5.14G [00:27<00:41, 95.0MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  24% 1.24G/5.14G [00:27<00:40, 97.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  94% 1.31G/1.39G [00:27<00:00, 98.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  24% 1.25G/5.14G [00:27<00:39, 98.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  96% 1.33G/1.39G [00:28<00:00, 101MB/s] \u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  25% 1.27G/5.14G [00:27<00:39, 98.4MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  25% 1.28G/5.14G [00:27<00:39, 97.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  97% 1.35G/1.39G [00:28<00:00, 105MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model.safetensors:  98% 1.36G/1.39G [00:28<00:00, 104MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  25% 1.30G/5.14G [00:27<00:37, 101MB/s] \u001b[A\n",
            "\n",
            "\n",
            "model.safetensors: 100% 1.38G/1.39G [00:28<00:00, 108MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors: 100% 1.39G/1.39G [00:28<00:00, 48.7MB/s]\n",
            "Fetching 18 files:  33% 6/18 [00:29<01:16,  6.40s/it]\n",
            "diffusion_pytorch_model.safetensors:  26% 1.34G/5.14G [00:28<00:33, 113MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  27% 1.36G/5.14G [00:28<00:32, 116MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  27% 1.38G/5.14G [00:28<00:31, 120MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  27% 1.41G/5.14G [00:28<00:31, 120MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  28% 1.43G/5.14G [00:28<00:31, 117MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  28% 1.45G/5.14G [00:29<00:31, 116MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  29% 1.47G/5.14G [00:29<00:31, 117MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  29% 1.49G/5.14G [00:29<00:30, 120MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  29% 1.51G/5.14G [00:29<00:29, 122MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  30% 1.53G/5.14G [00:29<00:28, 124MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  30% 1.55G/5.14G [00:29<00:28, 126MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  31% 1.57G/5.14G [00:30<00:28, 123MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  31% 1.59G/5.14G [00:30<00:28, 123MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  31% 1.61G/5.14G [00:30<00:28, 125MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  32% 1.64G/5.14G [00:30<00:27, 125MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  32% 1.66G/5.14G [00:30<00:27, 127MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  33% 1.68G/5.14G [00:30<00:26, 128MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  33% 1.70G/5.14G [00:31<00:27, 126MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  33% 1.72G/5.14G [00:31<00:27, 123MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  34% 1.74G/5.14G [00:31<00:28, 119MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  34% 1.76G/5.14G [00:33<02:14, 25.2MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  35% 1.77G/5.14G [00:33<01:56, 28.8MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  35% 1.79G/5.14G [00:34<01:26, 38.4MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  35% 1.81G/5.14G [00:34<01:06, 49.8MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  36% 1.84G/5.14G [00:34<00:53, 61.8MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  36% 1.86G/5.14G [00:34<00:44, 73.6MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  37% 1.88G/5.14G [00:34<00:39, 81.9MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  37% 1.90G/5.14G [00:34<00:36, 89.6MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  37% 1.92G/5.14G [00:35<00:33, 94.9MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  38% 1.94G/5.14G [00:35<00:31, 101MB/s] \u001b[A\n",
            "diffusion_pytorch_model.safetensors:  38% 1.96G/5.14G [00:35<00:29, 109MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  39% 1.98G/5.14G [00:35<00:27, 115MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  39% 2.00G/5.14G [00:35<00:26, 120MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  39% 2.02G/5.14G [00:35<00:25, 122MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  40% 2.04G/5.14G [00:36<00:25, 120MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  40% 2.07G/5.14G [00:36<00:26, 116MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  41% 2.09G/5.14G [00:36<00:26, 115MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  41% 2.11G/5.14G [00:36<00:25, 117MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  41% 2.13G/5.14G [00:36<00:25, 117MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  42% 2.15G/5.14G [00:37<01:01, 48.3MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  42% 2.17G/5.14G [00:38<00:49, 59.5MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  43% 2.19G/5.14G [00:38<00:41, 71.0MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  43% 2.21G/5.14G [00:38<00:36, 80.9MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  43% 2.23G/5.14G [00:38<00:31, 91.1MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  44% 2.25G/5.14G [00:38<00:29, 98.3MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  44% 2.28G/5.14G [00:38<00:27, 106MB/s] \u001b[A\n",
            "diffusion_pytorch_model.safetensors:  45% 2.30G/5.14G [00:39<00:25, 110MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  45% 2.32G/5.14G [00:39<00:24, 116MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  46% 2.34G/5.14G [00:39<00:23, 118MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  46% 2.36G/5.14G [00:39<00:23, 118MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  46% 2.38G/5.14G [00:39<00:23, 118MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  47% 2.40G/5.14G [00:39<00:22, 119MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  47% 2.42G/5.14G [00:40<00:22, 122MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  48% 2.44G/5.14G [00:40<00:21, 125MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  48% 2.46G/5.14G [00:40<00:21, 127MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  48% 2.49G/5.14G [00:40<00:20, 129MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  49% 2.51G/5.14G [00:40<00:20, 128MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  49% 2.53G/5.14G [00:40<00:21, 124MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  50% 2.55G/5.14G [00:41<00:21, 121MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  50% 2.57G/5.14G [00:41<00:21, 119MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  50% 2.59G/5.14G [00:41<00:21, 117MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  51% 2.61G/5.14G [00:41<00:21, 116MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  51% 2.63G/5.14G [00:43<01:14, 33.6MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  52% 2.65G/5.14G [00:43<00:57, 43.3MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  52% 2.67G/5.14G [00:43<00:46, 53.2MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  52% 2.69G/5.14G [00:43<00:38, 63.9MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  53% 2.72G/5.14G [00:44<00:32, 73.5MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  53% 2.74G/5.14G [00:44<00:30, 79.8MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  54% 2.76G/5.14G [00:44<00:28, 84.7MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  54% 2.77G/5.14G [00:44<00:27, 86.6MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  54% 2.78G/5.14G [00:44<00:26, 88.0MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  55% 2.80G/5.14G [00:44<00:24, 96.7MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  55% 2.82G/5.14G [00:45<00:22, 102MB/s] \u001b[A\n",
            "diffusion_pytorch_model.safetensors:  55% 2.84G/5.14G [00:45<00:21, 106MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  56% 2.86G/5.14G [00:45<00:20, 112MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  56% 2.88G/5.14G [00:45<00:19, 115MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  57% 2.90G/5.14G [00:45<00:19, 112MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  57% 2.93G/5.14G [00:45<00:19, 114MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  57% 2.95G/5.14G [00:46<00:19, 115MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  58% 2.97G/5.14G [00:46<00:18, 114MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  58% 2.99G/5.14G [00:46<00:18, 114MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  59% 3.01G/5.14G [00:47<00:49, 43.2MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  59% 3.03G/5.14G [00:47<00:38, 54.2MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  59% 3.05G/5.14G [00:47<00:31, 65.8MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  60% 3.07G/5.14G [00:48<00:27, 76.0MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  60% 3.09G/5.14G [00:48<00:29, 68.3MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  61% 3.11G/5.14G [00:48<00:25, 79.6MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  61% 3.14G/5.14G [00:48<00:22, 90.3MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  61% 3.16G/5.14G [00:49<00:19, 99.6MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  62% 3.18G/5.14G [00:49<00:18, 106MB/s] \u001b[A\n",
            "diffusion_pytorch_model.safetensors:  62% 3.20G/5.14G [00:49<00:17, 110MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  63% 3.22G/5.14G [00:49<00:17, 111MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  63% 3.24G/5.14G [00:49<00:17, 111MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  64% 3.26G/5.14G [00:49<00:16, 116MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  64% 3.28G/5.14G [00:50<00:15, 120MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  64% 3.30G/5.14G [00:50<00:15, 122MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  65% 3.32G/5.14G [00:50<00:14, 125MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  65% 3.34G/5.14G [00:50<00:14, 126MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  66% 3.37G/5.14G [00:50<00:14, 125MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  66% 3.39G/5.14G [00:50<00:15, 116MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  66% 3.41G/5.14G [00:51<00:14, 117MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  67% 3.43G/5.14G [00:51<00:14, 117MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  67% 3.45G/5.14G [00:51<00:14, 116MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  68% 3.47G/5.14G [00:53<00:52, 31.7MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  68% 3.49G/5.14G [00:53<00:40, 41.0MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  68% 3.51G/5.14G [00:53<00:31, 51.5MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  69% 3.53G/5.14G [00:53<00:25, 62.5MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  69% 3.55G/5.14G [00:53<00:21, 73.7MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  70% 3.58G/5.14G [00:54<00:18, 83.9MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  70% 3.60G/5.14G [00:54<00:16, 91.6MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  70% 3.62G/5.14G [00:54<00:15, 97.2MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  71% 3.64G/5.14G [00:54<00:14, 102MB/s] \u001b[A\n",
            "diffusion_pytorch_model.safetensors:  71% 3.66G/5.14G [00:54<00:13, 108MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  72% 3.68G/5.14G [00:54<00:12, 114MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  72% 3.70G/5.14G [00:55<00:12, 118MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  72% 3.72G/5.14G [00:55<00:11, 122MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  73% 3.74G/5.14G [00:55<00:11, 124MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  73% 3.76G/5.14G [00:55<00:11, 122MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  74% 3.79G/5.14G [00:55<00:11, 114MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  74% 3.81G/5.14G [00:56<00:12, 110MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  75% 3.83G/5.14G [00:56<00:12, 106MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  75% 3.85G/5.14G [00:56<00:12, 106MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  75% 3.87G/5.14G [00:58<00:41, 30.8MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  76% 3.89G/5.14G [00:58<00:31, 40.0MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  76% 3.91G/5.14G [00:58<00:24, 50.4MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  76% 3.92G/5.14G [00:58<00:21, 55.2MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  77% 3.94G/5.14G [00:58<00:17, 68.2MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  77% 3.96G/5.14G [00:59<00:14, 80.2MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  78% 3.98G/5.14G [00:59<00:13, 87.5MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  78% 4.01G/5.14G [00:59<00:11, 95.0MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  78% 4.03G/5.14G [00:59<00:11, 100MB/s] \u001b[A\n",
            "diffusion_pytorch_model.safetensors:  79% 4.05G/5.14G [00:59<00:10, 107MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  79% 4.07G/5.14G [00:59<00:09, 113MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  80% 4.09G/5.14G [01:00<00:08, 116MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  80% 4.11G/5.14G [01:00<00:08, 120MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  80% 4.13G/5.14G [01:00<00:08, 124MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  81% 4.15G/5.14G [01:00<00:07, 123MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  81% 4.17G/5.14G [01:00<00:08, 117MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  82% 4.19G/5.14G [01:01<00:10, 87.6MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  82% 4.22G/5.14G [01:01<00:09, 94.9MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  82% 4.24G/5.14G [01:01<00:08, 101MB/s] \u001b[A\n",
            "diffusion_pytorch_model.safetensors:  83% 4.26G/5.14G [01:03<00:28, 31.1MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  83% 4.28G/5.14G [01:03<00:21, 40.3MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  84% 4.30G/5.14G [01:03<00:16, 50.9MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  84% 4.32G/5.14G [01:03<00:13, 61.5MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  85% 4.34G/5.14G [01:03<00:10, 73.2MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  85% 4.36G/5.14G [01:04<00:09, 81.9MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  85% 4.38G/5.14G [01:04<00:08, 90.1MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  86% 4.40G/5.14G [01:04<00:07, 95.7MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  86% 4.42G/5.14G [01:04<00:06, 103MB/s] \u001b[A\n",
            "diffusion_pytorch_model.safetensors:  87% 4.45G/5.14G [01:04<00:06, 107MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  87% 4.47G/5.14G [01:04<00:05, 113MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  87% 4.49G/5.14G [01:05<00:05, 118MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  88% 4.51G/5.14G [01:05<00:05, 122MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  88% 4.53G/5.14G [01:05<00:04, 124MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  89% 4.55G/5.14G [01:05<00:04, 121MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  89% 4.57G/5.14G [01:05<00:04, 119MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  89% 4.59G/5.14G [01:05<00:04, 118MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  90% 4.61G/5.14G [01:06<00:04, 116MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  90% 4.63G/5.14G [01:06<00:04, 116MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  91% 4.66G/5.14G [01:08<00:14, 33.4MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  91% 4.67G/5.14G [01:08<00:12, 37.8MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  91% 4.68G/5.14G [01:08<00:10, 43.3MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  91% 4.69G/5.14G [01:08<00:12, 36.4MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  92% 4.71G/5.14G [01:08<00:08, 50.0MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  92% 4.73G/5.14G [01:09<00:06, 64.2MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  93% 4.75G/5.14G [01:09<00:05, 76.1MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  93% 4.77G/5.14G [01:09<00:04, 88.0MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  93% 4.79G/5.14G [01:09<00:03, 95.9MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  94% 4.81G/5.14G [01:09<00:03, 99.5MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  94% 4.83G/5.14G [01:09<00:02, 104MB/s] \u001b[A\n",
            "diffusion_pytorch_model.safetensors:  95% 4.85G/5.14G [01:10<00:02, 109MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  95% 4.88G/5.14G [01:10<00:02, 114MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  95% 4.90G/5.14G [01:10<00:02, 119MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  96% 4.92G/5.14G [01:10<00:01, 122MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  96% 4.94G/5.14G [01:10<00:01, 124MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  97% 4.96G/5.14G [01:10<00:01, 122MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  97% 4.98G/5.14G [01:11<00:01, 119MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  97% 5.00G/5.14G [01:11<00:01, 117MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  98% 5.02G/5.14G [01:11<00:01, 85.5MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  98% 5.04G/5.14G [01:11<00:00, 92.6MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  98% 5.05G/5.14G [01:12<00:02, 39.2MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  99% 5.06G/5.14G [01:13<00:02, 33.5MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  99% 5.09G/5.14G [01:13<00:01, 45.9MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors:  99% 5.11G/5.14G [01:13<00:00, 57.4MB/s]\u001b[A\n",
            "diffusion_pytorch_model.safetensors: 100% 5.14G/5.14G [01:13<00:00, 69.5MB/s]\n",
            "Fetching 18 files: 100% 18/18 [01:15<00:00,  4.18s/it]\n",
            "The config attributes {'controlnet_list': ['controlnet', 'RPMultiControlNetModel'], 'requires_aesthetics_score': False} were passed to StableDiffusionXLInstantIDPipeline, but are not expected and will be ignored. Please verify your model_index.json configuration file.\n",
            "Keyword arguments {'controlnet_list': ['controlnet', 'RPMultiControlNetModel'], 'requires_aesthetics_score': False, 'safety_checker': None} are not expected by StableDiffusionXLInstantIDPipeline and will be ignored.\n",
            "Loading pipeline components...: 100% 7/7 [00:03<00:00,  1.85it/s]\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://2db303df52b4884ff3.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
            "Start inference...\n",
            "[Debug] Prompt: watercolor painting, sexy pose. vibrant, beautiful, painterly, detailed, textural, artistic, \n",
            "[Debug] Neg Prompt: (lowres, low quality, worst quality:1.2), (text:1.2), watermark, anime, photorealistic, 35mm film, deformed, glitch, low contrast, noisy (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n",
            "Start inference...\n",
            "[Debug] Prompt: film noir style, ink sketch|vector, seductive pose of left side girl highly detailed, sharp focus, ultra sharpness, monochrome, high contrast, dramatic shadows, 1940s style, mysterious, cinematic, \n",
            "[Debug] Neg Prompt: (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n",
            "Start inference...\n",
            "[Debug] Prompt: vibrant colorful, ink sketch|vector|2d colors, at nightfall, sharp focus, sexy pose of left side girl, highly detailed, sharp focus, the clouds,colorful,ultra sharpness, \n",
            "[Debug] Neg Prompt: (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n",
            "Start inference...\n",
            "[Debug] Prompt: vibrant colorful, ink sketch|vector|2d colors, at nightfall, sharp focus, , highly detailed, sharp focus, the clouds,colorful,ultra sharpness, \n",
            "[Debug] Neg Prompt: (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n",
            "Start inference...\n",
            "[Debug] Prompt: watercolor painting, sexy pose. vibrant, beautiful, painterly, detailed, textural, artistic, \n",
            "[Debug] Neg Prompt: (lowres, low quality, worst quality:1.2), (text:1.2), watermark, anime, photorealistic, 35mm film, deformed, glitch, low contrast, noisy (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 495, in call_prediction\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1561, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1179, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 678, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 678, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/content/InstantID-hf/app.py\", line 227, in generate_image\n",
            "    images = pipe(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/InstantID-hf/pipeline_stable_diffusion_xl_instantid.py\", line 1105, in __call__\n",
            "    image = self.vae.decode(latents / self.vae.config.scaling_factor, return_dict=False)[0]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/utils/accelerate_utils.py\", line 46, in wrapper\n",
            "    return method(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/autoencoders/autoencoder_kl.py\", line 302, in decode\n",
            "    decoded = self._decode(z).sample\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/autoencoders/autoencoder_kl.py\", line 273, in _decode\n",
            "    dec = self.decoder(z)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/autoencoders/vae.py\", line 338, in forward\n",
            "    sample = up_block(sample, latent_embeds)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/unets/unet_2d_blocks.py\", line 2619, in forward\n",
            "    hidden_states = upsampler(hidden_states)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/upsampling.py\", line 184, in forward\n",
            "    hidden_states = self.conv(hidden_states, scale)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/lora.py\", line 358, in forward\n",
            "    return F.conv2d(\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.56 GiB. GPU 0 has a total capacty of 14.75 GiB of which 161.06 MiB is free. Process 14155 has 14.59 GiB memory in use. Of the allocated memory 12.80 GiB is allocated by PyTorch, and 1.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "Start inference...\n",
            "[Debug] Prompt: watercolor painting, sexy pose. vibrant, beautiful, painterly, detailed, textural, artistic, \n",
            "[Debug] Neg Prompt: (lowres, low quality, worst quality:1.2), (text:1.2), watermark, anime, photorealistic, 35mm film, deformed, glitch, low contrast, noisy (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 495, in call_prediction\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1561, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1179, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 678, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 678, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/content/InstantID-hf/app.py\", line 227, in generate_image\n",
            "    images = pipe(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/InstantID-hf/pipeline_stable_diffusion_xl_instantid.py\", line 1061, in __call__\n",
            "    noise_pred = self.unet(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/unets/unet_2d_condition.py\", line 1121, in forward\n",
            "    sample, res_samples = downsample_block(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/unets/unet_2d_blocks.py\", line 1199, in forward\n",
            "    hidden_states = attn(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/transformers/transformer_2d.py\", line 391, in forward\n",
            "    hidden_states = block(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/attention.py\", line 335, in forward\n",
            "    attn_output = self.attn1(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/attention_processor.py\", line 512, in forward\n",
            "    return self.processor(\n",
            "  File \"/content/InstantID-hf/ip_adapter/attention_processor.py\", line 73, in __call__\n",
            "    attention_probs = attn.get_attention_scores(query, key, attention_mask)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/attention_processor.py\", line 588, in get_attention_scores\n",
            "    attention_scores = torch.baddbmm(\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 880.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 159.06 MiB is free. Process 14155 has 14.59 GiB memory in use. Of the allocated memory 13.94 GiB is allocated by PyTorch, and 519.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "Start inference...\n",
            "[Debug] Prompt: watercolor painting, ultra sexy. vibrant, beautiful, painterly, detailed, textural, artistic, \n",
            "[Debug] Neg Prompt: (lowres, low quality, worst quality:1.2), (text:1.2), watermark, anime, photorealistic, 35mm film, deformed, glitch, low contrast, noisy (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 495, in call_prediction\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1561, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1179, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 678, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 678, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/content/InstantID-hf/app.py\", line 227, in generate_image\n",
            "    images = pipe(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/InstantID-hf/pipeline_stable_diffusion_xl_instantid.py\", line 1034, in __call__\n",
            "    down_block_res_samples, mid_block_res_sample = self.controlnet(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/controlnet.py\", line 804, in forward\n",
            "    sample, res_samples = downsample_block(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/unets/unet_2d_blocks.py\", line 1199, in forward\n",
            "    hidden_states = attn(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/transformers/transformer_2d.py\", line 391, in forward\n",
            "    hidden_states = block(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/attention.py\", line 400, in forward\n",
            "    ff_output = self.ff(norm_hidden_states, scale=lora_scale)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/attention.py\", line 672, in forward\n",
            "    hidden_states = module(hidden_states, scale)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/activations.py\", line 102, in forward\n",
            "    hidden_states, gate = self.proj(hidden_states, *args).chunk(2, dim=-1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/lora.py\", line 430, in forward\n",
            "    out = super().forward(hidden_states)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 94.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 81.06 MiB is free. Process 14155 has 14.67 GiB memory in use. Of the allocated memory 14.12 GiB is allocated by PyTorch, and 417.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2233, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/InstantID-hf/app.py\", line 412, in <module>\n",
            "    demo.launch(share=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2140, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2237, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/networking.py\", line 76, in close\n",
            "    self.thread.join()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 127.0.0.1:7860 <> https://2db303df52b4884ff3.gradio.live\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone -b dev https://github.com/camenduru/InstantID-hf\n",
        "%cd /content/InstantID-hf\n",
        "\n",
        "!apt -y install -qq aria2\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/InstantX/InstantID/raw/main/ControlNetModel/config.json -d /content/InstantID-hf/checkpoints/ControlNetModel -o config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/InstantX/InstantID/resolve/main/ControlNetModel/diffusion_pytorch_model.safetensors -d /content/InstantID-hf/checkpoints/ControlNetModel -o diffusion_pytorch_model.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/InstantX/InstantID/resolve/main/ip-adapter.bin -d /content/InstantID-hf/checkpoints -o ip-adapter.bin\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/spaces/InstantX/InstantID/resolve/main/models/antelopev2/1k3d68.onnx -d /content/InstantID-hf/models/antelopev2 -o 1k3d68.onnx\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/spaces/InstantX/InstantID/resolve/main/models/antelopev2/2d106det.onnx -d /content/InstantID-hf/models/antelopev2 -o 2d106det.onnx\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/spaces/InstantX/InstantID/resolve/main/models/antelopev2/genderage.onnx -d /content/InstantID-hf/models/antelopev2 -o genderage.onnx\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/spaces/InstantX/InstantID/resolve/main/models/antelopev2/glintr100.onnx -d /content/InstantID-hf/models/antelopev2 -o glintr100.onnx\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/spaces/InstantX/InstantID/resolve/main/models/antelopev2/scrfd_10g_bnkps.onnx -d /content/InstantID-hf/models/antelopev2 -o scrfd_10g_bnkps.onnx\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/spaces/InstantX/InstantID/resolve/main/examples/kaifu_resize.png -d /content/InstantID-hf/examples -o kaifu_resize.png\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/spaces/InstantX/InstantID/resolve/main/examples/sam_resize.png -d /content/InstantID-hf/examples -o sam_resize.png\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/spaces/InstantX/InstantID/resolve/main/examples/schmidhuber_resize.png -d /content/InstantID-hf/examples -o schmidhuber_resize.png\n",
        "\n",
        "!pip install -q insightface onnxruntime diffusers accelerate gradio==4.15.0\n",
        "!pip install -q https://download.pytorch.org/whl/cu121/xformers-0.0.22.post7-cp310-cp310-manylinux2014_x86_64.whl\n",
        "\n",
        "!python app.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V_FVwfcdL0QF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}