{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhnanjay/HuggingFace/blob/main/Custom_Retreivers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Retrievers - Simple Hybrid Search"
      ],
      "metadata": {
        "id": "6hNEREmjhXCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbxE1Z7fR-PA",
        "outputId": "e150d57a-619f-44a9-bd8a-298d875e0bf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.7.16-py3-none-any.whl (626 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.2/626.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken (from llama-index)\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dataclasses-json (from llama-index)\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Collecting langchain>=0.0.218 (from llama-index)\n",
            "  Downloading langchain-0.0.247-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=2.0.15 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2.0.19)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.22.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (8.2.2)\n",
            "Collecting openai>=0.26.4 (from llama-index)\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.3)\n",
            "Requirement already satisfied: urllib3<2 in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.26.16)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2023.6.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (4.7.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from llama-index) (4.11.2)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.6)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.218->llama-index) (6.0.1)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.218->llama-index) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.218->llama-index) (4.0.2)\n",
            "Collecting langsmith<0.1.0,>=0.0.11 (from langchain>=0.0.218->llama-index)\n",
            "  Downloading langsmith-0.0.15-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.218->llama-index) (2.8.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain>=0.0.218->llama-index)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.218->llama-index) (1.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.218->llama-index) (2.27.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai>=0.26.4->llama-index) (4.65.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=2.0.15->llama-index) (2.0.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->llama-index) (2.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2022.7.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->llama-index) (2022.10.31)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama-index) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama-index) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama-index) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama-index) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama-index) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->llama-index) (1.3.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index) (23.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain>=0.0.218->llama-index) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain>=0.0.218->llama-index) (3.4)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, tiktoken, openapi-schema-pydantic, langsmith, openai, dataclasses-json, langchain, llama-index\n",
            "Successfully installed dataclasses-json-0.5.14 langchain-0.0.247 langsmith-0.0.15 llama-index-0.7.16 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-0.27.8 openapi-schema-pydantic-1.2.4 tiktoken-0.4.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
      ],
      "metadata": {
        "id": "GlSXuf-UTvGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import (\n",
        "    VectorStoreIndex,\n",
        "    SimpleKeywordTableIndex,\n",
        "    SimpleDirectoryReader,\n",
        "    get_response_synthesizer,\n",
        "    ServiceContext,\n",
        "    StorageContext,\n",
        ")\n",
        "\n",
        "# import QueryBundle\n",
        "from llama_index import QueryBundle\n",
        "\n",
        "# import NodeWithScore\n",
        "from llama_index.schema import NodeWithScore\n",
        "\n",
        "# Retrievers\n",
        "from llama_index.retrievers import (\n",
        "    BaseRetriever,\n",
        "    VectorIndexRetriever,\n",
        "    KeywordTableSimpleRetriever,\n",
        ")\n",
        "\n",
        "from llama_index.query_engine import RetrieverQueryEngine\n",
        "\n",
        "from typing import List\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "import openai\n",
        "openai.api_key='YOUR OPENAI API KEY'"
      ],
      "metadata": {
        "id": "KW2YyJdJhU8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load documents\n",
        "documents = SimpleDirectoryReader(\"data\").load_data()\n",
        "\n",
        "# initialize service context (set chunk size)\n",
        "service_context = ServiceContext.from_defaults(chunk_size=1024)\n",
        "node_parser = service_context.node_parser\n",
        "\n",
        "nodes = node_parser.get_nodes_from_documents(documents)\n",
        "\n",
        "# initialize storage context (by default it's in-memory)\n",
        "storage_context = StorageContext.from_defaults()\n",
        "storage_context.docstore.add_documents(nodes)\n",
        "\n",
        "# Build vector index\n",
        "vector_index = VectorStoreIndex(nodes, storage_context=storage_context)\n",
        "\n",
        "# Build keyword index\n",
        "keyword_index = SimpleKeywordTableIndex(nodes, storage_context=storage_context)"
      ],
      "metadata": {
        "id": "IXvwFz3RlQ6i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9762bfc6-637b-4246-e407-bd24df763780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomRetriever(BaseRetriever):\n",
        "    \"\"\"Custom retriever that performs both semantic search and hybrid search.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        vector_retriever: VectorIndexRetriever,\n",
        "        keyword_retriever: KeywordTableSimpleRetriever,\n",
        "        mode: str = \"AND\",\n",
        "    ) -> None:\n",
        "        \"\"\"Init params.\"\"\"\n",
        "\n",
        "        self._vector_retriever = vector_retriever\n",
        "        self._keyword_retriever = keyword_retriever\n",
        "        if mode not in (\"AND\", \"OR\"):\n",
        "            raise ValueError(\"Invalid mode.\")\n",
        "        self._mode = mode\n",
        "\n",
        "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
        "        \"\"\"Retrieve nodes given query.\"\"\"\n",
        "\n",
        "        vector_nodes = self._vector_retriever.retrieve(query_bundle)\n",
        "        keyword_nodes = self._keyword_retriever.retrieve(query_bundle)\n",
        "\n",
        "        vector_ids = {n.node.node_id for n in vector_nodes}\n",
        "        keyword_ids = {n.node.node_id for n in keyword_nodes}\n",
        "\n",
        "        combined_dict = {n.node.node_id: n for n in vector_nodes}\n",
        "        combined_dict.update({n.node.node_id: n for n in keyword_nodes})\n",
        "\n",
        "        if self._mode == \"AND\":\n",
        "            retrieve_ids = vector_ids.intersection(keyword_ids)\n",
        "        else:\n",
        "            retrieve_ids = vector_ids.union(keyword_ids)\n",
        "\n",
        "        retrieve_nodes = [combined_dict[rid] for rid in retrieve_ids]\n",
        "        return retrieve_nodes"
      ],
      "metadata": {
        "id": "uUlvmzJQltJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define custom retriever\n",
        "vector_retriever = VectorIndexRetriever(index=vector_index, similarity_top_k=2)\n",
        "keyword_retriever = KeywordTableSimpleRetriever(index=keyword_index)\n",
        "custom_retriever = CustomRetriever(vector_retriever, keyword_retriever)\n",
        "\n",
        "# define response synthesizer\n",
        "response_synthesizer = get_response_synthesizer()\n",
        "\n",
        "# assemble query engine\n",
        "custom_query_engine = RetrieverQueryEngine(\n",
        "    retriever=custom_retriever,\n",
        "    response_synthesizer=response_synthesizer,\n",
        ")\n",
        "\n",
        "# vector query engine\n",
        "vector_query_engine = RetrieverQueryEngine(\n",
        "    retriever=vector_retriever,\n",
        "    response_synthesizer=response_synthesizer,\n",
        ")\n",
        "# keyword query engine\n",
        "keyword_query_engine = RetrieverQueryEngine(\n",
        "    retriever=keyword_retriever,\n",
        "    response_synthesizer=response_synthesizer,\n",
        ")"
      ],
      "metadata": {
        "id": "VQ8e2n7ClzFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = custom_query_engine.query(\"What did the author do during his time at YC?\")\n",
        "# print the synthesized response.\n",
        "display(HTML(f'<p style=\"font-size:20px\">{response.response}</p>'))"
      ],
      "metadata": {
        "id": "9wCMIy_jl8gR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "28b7aa1d-f2e8-4fd0-e10f-939173d134d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"font-size:20px\">\n",
              "The author worked on YC in a variety of ways. He wrote essays, worked on internal software in Arc, and created Hacker News. He also helped select and support founders, dealt with disputes between cofounders, and fought with people who maltreated the startups. He worked hard even at the parts he didn't like, and eventually offered to hand YC over to someone else. He then spent the rest of his time at YC helping the startups get through Demo Day before he left.</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hybrid search can allow us to not retrieve nodes that are irrelevant\n",
        "# Yale is never mentioned in the essay\n",
        "response = custom_query_engine.query(\"What did the author do during his time at Yale?\")"
      ],
      "metadata": {
        "id": "2upf4yU3l_cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the synthesized response.\n",
        "display(HTML(f'<p style=\"font-size:20px\">{response.response}</p>'))"
      ],
      "metadata": {
        "id": "Bz-FFd42mFog",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4fdf9ce6-2982-44ec-9070-8d6f6bb0b140"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"font-size:20px\">None</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(response.source_nodes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZPMBOmRduzu",
        "outputId": "43bd584d-1def-47e6-df9d-a08e5cb84f84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector search\n",
        "response = vector_query_engine.query(\"What did the author do during his time at Yale?\")\n",
        "\n",
        "# print the synthesized response.\n",
        "display(HTML(f'<p style=\"font-size:20px\">{response.response}</p>'))"
      ],
      "metadata": {
        "id": "EMXyM0oymKhz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "804cab0b-dd9a-483d-873f-7faa1832e95e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"font-size:20px\">\n",
              "The author did not attend Yale. The context information provided is about the author's work before and after college.</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(response.source_nodes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfjIjKralX03",
        "outputId": "8c2aa1dd-4305-4362-d2d6-87502a9059af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yzsufDXfla2D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}