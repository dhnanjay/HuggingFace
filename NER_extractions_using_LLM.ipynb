{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzN431na+YK4sGB0uZm78b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhnanjay/HuggingFace/blob/main/NER_extractions_using_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyGMv_GZwIB1",
        "outputId": "0c9c60c9-03c5-488b-c48a-4d75109901a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: py-llm-core in /usr/local/lib/python3.10/dist-packages (2.8.11)\n",
            "Requirement already satisfied: openai<2,>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from py-llm-core) (1.35.3)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from py-llm-core) (0.7.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from py-llm-core) (4.19.2)\n",
            "Requirement already satisfied: dirtyjson in /usr/local/lib/python3.10/dist-packages (from py-llm-core) (1.0.8)\n",
            "Requirement already satisfied: llama-cpp-python>=0.2.20 in /usr/local/lib/python3.10/dist-packages (from py-llm-core) (0.2.79)\n",
            "Requirement already satisfied: python-decouple in /usr/local/lib/python3.10/dist-packages (from py-llm-core) (3.8)\n",
            "Requirement already satisfied: mistralai in /usr/local/lib/python3.10/dist-packages (from py-llm-core) (0.4.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python>=0.2.20->py-llm-core) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python>=0.2.20->py-llm-core) (1.25.2)\n",
            "Requirement already satisfied: diskcache>=5.6.1 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python>=0.2.20->py-llm-core) (5.6.3)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python>=0.2.20->py-llm-core) (3.1.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2,>=1.3.5->py-llm-core) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2,>=1.3.5->py-llm-core) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2,>=1.3.5->py-llm-core) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai<2,>=1.3.5->py-llm-core) (2.7.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2,>=1.3.5->py-llm-core) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2,>=1.3.5->py-llm-core) (4.66.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->py-llm-core) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->py-llm-core) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->py-llm-core) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->py-llm-core) (0.18.1)\n",
            "Requirement already satisfied: orjson<3.11,>=3.9.10 in /usr/local/lib/python3.10/dist-packages (from mistralai->py-llm-core) (3.10.5)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->py-llm-core) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->py-llm-core) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2,>=1.3.5->py-llm-core) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2,>=1.3.5->py-llm-core) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2,>=1.3.5->py-llm-core) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2,>=1.3.5->py-llm-core) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2,>=1.3.5->py-llm-core) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python>=0.2.20->py-llm-core) (2.1.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai<2,>=1.3.5->py-llm-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai<2,>=1.3.5->py-llm-core) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->py-llm-core) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->py-llm-core) (2.0.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install py-llm-core\n",
        "# https://github.com/advanced-stack/py-llm-core?tab=readme-ov-file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir -p ~/.cache/py-llm-core/models\n",
        "%cd ~/.cache/py-llm-core/models\n",
        "# !wget -O nuextract-tiny https://huggingface.co/advanced-stack/NuExtract-tiny-GGUF/resolve/main/nuextract-tiny-f16.gguf?download=true"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91HpoSG_wOen",
        "outputId": "7ee0370f-2854-47f5-f09b-6e4e751024e5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.cache/py-llm-core/models\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UsageError: Line magic function `%wget` not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O nuextract-tiny https://huggingface.co/advanced-stack/NuExtract-tiny-GGUF/resolve/main/nuextract-tiny-f16.gguf?download=true"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAzWn4Qxw_N9",
        "outputId": "6d7c33e5-cfbf-4cdb-ee9f-3b22cb165906"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-25 18:59:03--  https://huggingface.co/advanced-stack/NuExtract-tiny-GGUF/resolve/main/nuextract-tiny-f16.gguf?download=true\n",
            "Resolving huggingface.co (huggingface.co)... 18.172.134.124, 18.172.134.24, 18.172.134.4, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.172.134.124|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.huggingface.co/repos/ba/6f/ba6f9b7771682fa7863e549a2b715b9c972dcd0f9885ed9bbae6d127b8b71dd3/0a0b03c6139d2318bcaf824666968bcf7e7709c9bd7d2495f9b05e71cb8ce4b6?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27nuextract-tiny-f16.gguf%3B+filename%3D%22nuextract-tiny-f16.gguf%22%3B&Expires=1719601143&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxOTYwMTE0M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2JhLzZmL2JhNmY5Yjc3NzE2ODJmYTc4NjNlNTQ5YTJiNzE1YjljOTcyZGNkMGY5ODg1ZWQ5YmJhZTZkMTI3YjhiNzFkZDMvMGEwYjAzYzYxMzlkMjMxOGJjYWY4MjQ2NjY5NjhiY2Y3ZTc3MDljOWJkN2QyNDk1ZjliMDVlNzFjYjhjZTRiNj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=W5xQ4zByXXkiQ9dKnb7Cmy5FljEQIJPZYFTNp6fInzIrAoe3xkTlAhg%7EoWQcjnIvSWEBFQnoGtXs1ECUZruevKwNFjobNONyb3HV17fSNw9yCMWyTchkgyGewtRDJWkkpx1Nashg7wRAqvGGSG1A1Mnl8MNHc8jI12z5ywo9LOi1QDabfbyJa8ouj43gWdC3ItGl2XKXR6TB26k1UbvW3znPJuPpdUQgmkH00QHFLfm4j5mUszpZma7CVlJpuzf2kB8VIdWfPhS6e4CbMOSQx4sJCD3QYPHsE2j4vFeNXyDK5AZgTnF6WxrY-dYSFmfC%7EqYAh4Llw-LORzonJsweWw__&Key-Pair-Id=K2FPYV99P2N66Q [following]\n",
            "--2024-06-25 18:59:03--  https://cdn-lfs-us-1.huggingface.co/repos/ba/6f/ba6f9b7771682fa7863e549a2b715b9c972dcd0f9885ed9bbae6d127b8b71dd3/0a0b03c6139d2318bcaf824666968bcf7e7709c9bd7d2495f9b05e71cb8ce4b6?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27nuextract-tiny-f16.gguf%3B+filename%3D%22nuextract-tiny-f16.gguf%22%3B&Expires=1719601143&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxOTYwMTE0M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2JhLzZmL2JhNmY5Yjc3NzE2ODJmYTc4NjNlNTQ5YTJiNzE1YjljOTcyZGNkMGY5ODg1ZWQ5YmJhZTZkMTI3YjhiNzFkZDMvMGEwYjAzYzYxMzlkMjMxOGJjYWY4MjQ2NjY5NjhiY2Y3ZTc3MDljOWJkN2QyNDk1ZjliMDVlNzFjYjhjZTRiNj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=W5xQ4zByXXkiQ9dKnb7Cmy5FljEQIJPZYFTNp6fInzIrAoe3xkTlAhg%7EoWQcjnIvSWEBFQnoGtXs1ECUZruevKwNFjobNONyb3HV17fSNw9yCMWyTchkgyGewtRDJWkkpx1Nashg7wRAqvGGSG1A1Mnl8MNHc8jI12z5ywo9LOi1QDabfbyJa8ouj43gWdC3ItGl2XKXR6TB26k1UbvW3znPJuPpdUQgmkH00QHFLfm4j5mUszpZma7CVlJpuzf2kB8VIdWfPhS6e4CbMOSQx4sJCD3QYPHsE2j4vFeNXyDK5AZgTnF6WxrY-dYSFmfC%7EqYAh4Llw-LORzonJsweWw__&Key-Pair-Id=K2FPYV99P2N66Q\n",
            "Resolving cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)... 108.156.107.29, 108.156.107.44, 108.156.107.80, ...\n",
            "Connecting to cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)|108.156.107.29|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 934168480 (891M) [binary/octet-stream]\n",
            "Saving to: ‘nuextract-tiny’\n",
            "\n",
            "nuextract-tiny      100%[===================>] 890.89M  48.5MB/s    in 21s     \n",
            "\n",
            "2024-06-25 18:59:25 (41.5 MB/s) - ‘nuextract-tiny’ saved [934168480/934168480]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "from llm_core.parsers import NuExtractParser\n",
        "\n",
        "#: NuExtract model needs default values for the class fields\n",
        "@dataclass\n",
        "class Book:\n",
        "    title: str = \"\"\n",
        "    summary: str = \"\"\n",
        "    author: str = \"\"\n",
        "    published_year: int = \"\"\n",
        "\n",
        "\n",
        "text = \"\"\"Foundation is a science fiction novel by American writer\n",
        "Isaac Asimov. It is the first published in his Foundation Trilogy (later\n",
        "expanded into the Foundation series). Foundation is a cycle of five\n",
        "interrelated short stories, first published as a single book by Gnome Press\n",
        "in 1951. Collectively they tell the early story of the Foundation,\n",
        "an institute founded by psychohistorian Hari Seldon to preserve the best\n",
        "of galactic civilization after the collapse of the Galactic Empire.\n",
        "\"\"\"\n",
        "\n",
        "with NuExtractParser(Book) as parser:\n",
        "    response = parser.parse(text)\n",
        "    print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENb7stexwXol",
        "outputId": "dabab670-06fb-4cf6-e22b-746a91ed0f66"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Book(title='Foundation', summary='a science fiction novel by American writer Isaac Asimov. It is the first published in his Foundation Trilogy (later expanded into the Foundation series). Foundation is a cycle of five interrelated short stories, first published as a single book by Gnome Press in 1951.', author='Isaac Asimov', published_year='1951')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "from llm_core.parsers import NuExtractParser\n",
        "\n",
        "#: NuExtract model needs default values for the class fields\n",
        "@dataclass\n",
        "class Memo:\n",
        "    Accounting_Subject: str = \"\"\n",
        "    Company_Name: str = \"\"\n",
        "    Date: str = \"\"\n",
        "\n",
        "\n",
        "text = \"\"\"\n",
        "To:                      Memorandum to Accounting File\n",
        "Prepared By:     CNM LLP, on behalf of Management\n",
        "Reviewed By:    Juan Ojeda, Controller\n",
        "Date:                  April 4, 2022\n",
        "Subject:             ASC 606 – Revenue Recognition Standard Policy\n",
        "Purpose:\n",
        "The purpose of this memo is to analyze and document the accounting for revenue recognition under Financial Accounting Standards Board (“FASB”) Accounting Standards Codification 606, Revenue From Contracts With Customers, as amended (“ASC 606”), by Ecosense Lighting, Inc. (“the Company”).\n",
        "Background:\n",
        "In May 2014, the FASB issued Account Standards Update (“ASU”) 2014-09, which provided a new framework for revenue recognition. The core principles of ASC 606 state that an entity should recognize revenue to depict the transfer of promised goods or services to customers in an amount that reflects the consideration to which the entity expects to be entitled in exchange for those goods or services. The guidance provides a five-step analysis to achieve those core principles:\n",
        "Identify the contract(s) with a customer\n",
        "Identify the performance obligations in the contract\n",
        "Determine the transaction price\n",
        "Allocate the transaction price to the performance obligations in the contract\n",
        "Recognize revenue when (or as) the entity satisfies a performance obligation\n",
        "Subsequent to ASU 2014-09, the FASB issued several authoritative guidance updates that amended various aspects of the new standard to clarify certain terms, guidance, and disclosure requirements. In particular, the updates amended principal versus agent guidance, accounting for shipping and handling costs, disclosure requirements for remaining performance obligations, impairment testing for contract costs and accrual of advertising costs, as well as clarifies several previous examples.\n",
        "ASC 606 was adopted by the Company with an effective date of January 1, 2019. As such, this technical analysis does not cover the Company’s initial adoption or implementation financial impact.\n",
        "Company Overview and Revenue Background:\n",
        "Ecosense Lighting was founded in 2009 and is an LED technology company. Ecosense is a team of LED lighting pioneers with over 100 years of combined[NP1]  experience and a genuine passion for delivering advanced solid-state lighting solutions. Ecosense delivers a broad line of high-quality, cutting-edge LED\n",
        "  [NP1]Add this for clarity--please advise if you agree\n",
        "\"\"\"\n",
        "\n",
        "with NuExtractParser(Memo) as parser:\n",
        "    response = parser.parse(text)\n",
        "    print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cV7u_xW3xH4P",
        "outputId": "d8424b00-0aef-40b0-e236-da7f09f85ce3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memo(Accounting_Subject='Revenue Recognition Standard Policy', Company_Name='Ecosense Lighting, Inc.', Date='April 4, 2022')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IrwdQ8Ijx9Hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hkSqGjhr1Gna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CDLMtifB1GpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U-YkhHKC1GrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "\n",
        "def predict_NuExtract(model,tokenizer,text, schema,example = [\"\",\"\",\"\"]):\n",
        "    schema = json.dumps(json.loads(schema), indent=4)\n",
        "    input_llm =  \"<|input|>\\n### Template:\\n\" +  schema + \"\\n\"\n",
        "    for i in example:\n",
        "      if i != \"\":\n",
        "          input_llm += \"### Example:\\n\"+ json.dumps(json.loads(i), indent=4)+\"\\n\"\n",
        "\n",
        "    input_llm +=  \"### Text:\\n\"+text +\"\\n<|output|>\\n\"\n",
        "    input_ids = tokenizer(input_llm, return_tensors=\"pt\",truncation = True, max_length = 4000)#.to(\"cuda\")\n",
        "\n",
        "    output = tokenizer.decode(model.generate(**input_ids)[0], skip_special_tokens=True)\n",
        "    return output.split(\"<|output|>\")[1].split(\"<|end-output|>\")[0]\n",
        "\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"numind/NuExtract-tiny\", trust_remote_code=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"numind/NuExtract-tiny\", trust_remote_code=True)\n",
        "\n",
        "# model.to(\"cuda\")\n",
        "\n",
        "model.eval()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iM74gdjA1Gtk",
        "outputId": "cfc9f4ae-cc75-4e3d-8d4e-9b7858ec0852"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Qwen2ForCausalLM(\n",
              "  (model): Qwen2Model(\n",
              "    (embed_tokens): Embedding(151936, 1024)\n",
              "    (layers): ModuleList(\n",
              "      (0-23): 24 x Qwen2DecoderLayer(\n",
              "        (self_attn): Qwen2SdpaAttention(\n",
              "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "          (rotary_emb): Qwen2RotaryEmbedding()\n",
              "        )\n",
              "        (mlp): Qwen2MLP(\n",
              "          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen2RMSNorm()\n",
              "        (post_attention_layernorm): Qwen2RMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (norm): Qwen2RMSNorm()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "text = \"\"\"We introduce Mistral 7B, a 7–billion-parameter language model engineered for\n",
        "superior performance and efficiency. Mistral 7B outperforms the best open 13B\n",
        "model (Llama 2) across all evaluated benchmarks, and the best released 34B\n",
        "model (Llama 1) in reasoning, mathematics, and code generation. Our model\n",
        "leverages grouped-query attention (GQA) for faster inference, coupled with sliding\n",
        "window attention (SWA) to effectively handle sequences of arbitrary length with a\n",
        "reduced inference cost. We also provide a model fine-tuned to follow instructions,\n",
        "Mistral 7B – Instruct, that surpasses Llama 2 13B – chat model both on human and\n",
        "automated benchmarks. Our models are released under the Apache 2.0 license.\n",
        "Code: https://github.com/mistralai/mistral-src\n",
        "Webpage: https://mistral.ai/news/announcing-mistral-7b/\"\"\"\n",
        "\n",
        "schema = \"\"\"{\n",
        "    \"Model\": {\n",
        "        \"Name\": \"\",\n",
        "        \"Number of parameters\": \"\",\n",
        "        \"Number of max token\": \"\",\n",
        "        \"Architecture\": []\n",
        "    },\n",
        "    \"Usage\": {\n",
        "        \"Use case\": [],\n",
        "        \"Licence\": \"\"\n",
        "    }\n",
        "}\"\"\"\n",
        "\n",
        "prediction = predict_NuExtract(model,tokenizer,text, schema,example = [\"\",\"\",\"\"])\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgAvFzFJ1MCW",
        "outputId": "0fd4b22c-c563-452d-d332-97e0ad728299"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151646 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "{\n",
            "    \"Model\": {\n",
            "        \"Name\": \"Mistral 7B\",\n",
            "        \"Number of parameters\": \"7 billion\",\n",
            "        \"Number of max token\": \"\",\n",
            "        \"Architecture\": [\n",
            "            \"grouped-query attention (GQA)\",\n",
            "            \"sliding window attention (SWA)\"\n",
            "        ]\n",
            "    },\n",
            "    \"Usage\": {\n",
            "        \"Use case\": [\n",
            "            \"reasoning\",\n",
            "            \"mathematics\",\n",
            "            \"code generation\"\n",
            "        ],\n",
            "        \"Licence\": \"Apache 2.0\"\n",
            "    }\n",
            "}\n",
            "\n",
            "CPU times: user 33.4 s, sys: 417 ms, total: 33.8 s\n",
            "Wall time: 36.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "text = \"\"\"\n",
        "To:                      Memorandum to Accounting File\n",
        "Prepared By:     CNM LLP, on behalf of Management\n",
        "Reviewed By:    Juan Ojeda, Controller\n",
        "Date:                  April 4, 2022\n",
        "Subject:             ASC 606 – Revenue Recognition Standard Policy\n",
        "Purpose:\n",
        "The purpose of this memo is to analyze and document the accounting for revenue recognition under Financial Accounting Standards Board (“FASB”) Accounting Standards Codification 606, Revenue From Contracts With Customers, as amended (“ASC 606”), by Ecosense Lighting, Inc. (“the Company”).\n",
        "Background:\n",
        "In May 2014, the FASB issued Account Standards Update (“ASU”) 2014-09, which provided a new framework for revenue recognition. The core principles of ASC 606 state that an entity should recognize revenue to depict the transfer of promised goods or services to customers in an amount that reflects the consideration to which the entity expects to be entitled in exchange for those goods or services. The guidance provides a five-step analysis to achieve those core principles:\n",
        "Identify the contract(s) with a customer\n",
        "Identify the performance obligations in the contract\n",
        "Determine the transaction price\n",
        "Allocate the transaction price to the performance obligations in the contract\n",
        "Recognize revenue when (or as) the entity satisfies a performance obligation\n",
        "Subsequent to ASU 2014-09, the FASB issued several authoritative guidance updates that amended various aspects of the new standard to clarify certain terms, guidance, and disclosure requirements. In particular, the updates amended principal versus agent guidance, accounting for shipping and handling costs, disclosure requirements for remaining performance obligations, impairment testing for contract costs and accrual of advertising costs, as well as clarifies several previous examples.\n",
        "ASC 606 was adopted by the Company with an effective date of January 1, 2019. As such, this technical analysis does not cover the Company’s initial adoption or implementation financial impact.\n",
        "Company Overview and Revenue Background:\n",
        "Ecosense Lighting was founded in 2009 and is an LED technology company. Ecosense is a team of LED lighting pioneers with over 100 years of combined[NP1]  experience and a genuine passion for delivering advanced solid-state lighting solutions. Ecosense delivers a broad line of high-quality, cutting-edge LED\n",
        "  [NP1]Add this for clarity--please advise if you agree\n",
        "\"\"\"\n",
        "\n",
        "# schema = \"\"\"{\n",
        "#     \"Accounting Memo\": {\n",
        "#         \"Accounting Subject\": \"\",\n",
        "#         \"Company Name\": \"\",\n",
        "#         \"Date\": \"\",\n",
        "#     },\n",
        "# }\"\"\"\n",
        "\n",
        "schema = \"\"\"{\n",
        "\n",
        "    \"Accounting Memo\": {\n",
        "\n",
        "        \"Accounting Subject\": \"\",\n",
        "\n",
        "        \"Company Name\": \"\",\n",
        "\n",
        "        \"Date\": \"\"\n",
        "\n",
        "    }\n",
        "\n",
        "}\"\"\"\n",
        "\n",
        "prediction = predict_NuExtract(model,tokenizer,text, schema,example = [\"\",\"\",\"\"])\n",
        "print(prediction)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8Y8Ai8a1YB_",
        "outputId": "8a822a56-2dbc-4188-f609-9fcd21e7723f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151646 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "{\n",
            "    \"Accounting Memo\": {\n",
            "        \"Accounting Subject\": \"ASC 606 \\u2013 Revenue Recognition Standard Policy\",\n",
            "        \"Company Name\": \"Ecosense Lighting, Inc.\",\n",
            "        \"Date\": \"April 4, 2022\"\n",
            "    }\n",
            "}\n",
            "\n",
            "CPU times: user 29.5 s, sys: 472 ms, total: 30 s\n",
            "Wall time: 32.3 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nJAnIyF2M0S",
        "outputId": "6b0cf8be-7f75-48a1-d23d-5c32a0a4665d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: transformers\n",
            "Version: 4.41.2\n",
            "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
            "Home-page: https://github.com/huggingface/transformers\n",
            "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
            "Author-email: transformers@huggingface.co\n",
            "License: Apache 2.0 License\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " \"Purpose\": \"\",\n",
        "\n",
        "        \"Simple or Policy Memo\": \"\",\n"
      ],
      "metadata": {
        "id": "9L3dh5jN37Cw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}